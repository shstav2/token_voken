{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "former-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distributed-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/staveshemesh/Projects/shstav2/token_voken/src')\n",
    "sys.path.append('/Users/staveshemesh/Projects/shstav2/token_voken')\n",
    "from src.common.setup import syspath_append_projects\n",
    "syspath_append_projects()\n",
    "from src.common.path_resolvers import *\n",
    "from src.common.constants import *\n",
    "from src.common.display_utils import *\n",
    "from src.common.commands import *\n",
    "from src.common.status import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strange-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/Users/staveshemesh/Projects/shstav2/token_voken/data'\n",
    "INTERVALS_FILE = 'df_intervals_batch2_500_20210515_195921.csv'\n",
    "INTERVALS_PATH = os.path.join(DATA_ROOT, INTERVALS_FILE)\n",
    "\n",
    "TIMESTR = time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-doctor",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "everyday-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intervals = pd.read_csv(INTERVALS_PATH, dtype={'interval_id': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "detailed-disclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intervals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-toner",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-earthquake",
   "metadata": {},
   "source": [
    "## MTCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "muslim-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, UnidentifiedImageError\n",
    "from facenet_pytorch import MTCNN, extract_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "existing-might",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-94f08faf76ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmtcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_largest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/facenet_pytorch/models/mtcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_size, margin, min_face_size, thresholds, factor, post_process, select_largest, selection_method, keep_all, device)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection_method\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.8/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "mtcnn = MTCNN(keep_all=False, select_largest=False, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spoken-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_every = 187\n",
    "\n",
    "def save_faces(interval_id, frame_filename, debug=False):\n",
    "    frame_id, frame_path = resolve_paths(frame_filename, interval_id)\n",
    "    \n",
    "    image = Image.open(frame_path)\n",
    "    boxes, probs, points = mtcnn.detect(image, landmarks=True)\n",
    "    img_draw = image.copy()\n",
    "    draw = ImageDraw.Draw(img_draw)\n",
    "    \n",
    "    for i, (box, point) in enumerate(zip(boxes, points)):\n",
    "        draw.rectangle(box.tolist(), width=5)\n",
    "        for p in point:\n",
    "            draw.rectangle((p - 10).tolist() + (p + 10).tolist(), width=10)\n",
    "        detected_face_path = resolve_detected_face_path(interval_id, frame_id, i, create=True)\n",
    "        extract_face(image, box, image_size=224, margin=70, save_path=detected_face_path)\n",
    "    \n",
    "    annotated_faces_path = resolve_annot_faces_path(interval_id, frame_id)\n",
    "    img_draw.save(annotated_faces_path)\n",
    "    \n",
    "    debug_print(debug, frame_filename, frame_id, annotated_faces_path, probs)\n",
    "    \n",
    "\n",
    "def debug_print(debug, frame_filename, frame_id, annotated_faces_path, probs):\n",
    "    should_display = debug or ('000.png' in frame_filename)\n",
    "    if should_display:\n",
    "        print(f'Frame id: {frame_id}. Ouput dir: {annotated_faces_path}..')\n",
    "        print(f'probs: {probs}')\n",
    "        display(IPython.display.Image(annotated_faces_path, height=500, width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "physical-relay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cardiovascular-entity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "addressed-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/staveshemesh/Projects/Youtube/oliver/Tt-mpuR_QHQ/100913/vokens/face_annot_224'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolve_interval_face_annot_224_dir('100913')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_sample = False\n",
    "if do_sample:\n",
    "    # Just a sample test\n",
    "    for idx, row in tqdm(df_inervals_batch1[['interval_id', 'interval_frames_dir']][1:3].iterrows()):\n",
    "        interval_id, frames_dir = row['interval_id'], row['interval_frames_dir']\n",
    "        print(frames_dir)\n",
    "        frames = sorted(os.listdir(frames_dir))\n",
    "        for frame_filename in tqdm(frames):\n",
    "            if frame_filename.endswith(\".png\"):\n",
    "                save_faces(interval_id, frame_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a sample test\n",
    "for idx, row in tqdm(df_inervals_batch1[['interval_id', 'interval_frames_dir']][:4].iterrows()):\n",
    "    interval_id, frames_dir = row['interval_id'], row['interval_frames_dir']\n",
    "    print(frames_dir)\n",
    "    frames = sorted(os.listdir(frames_dir))\n",
    "    for frame_filename in tqdm(frames[:3]):\n",
    "        if frame_filename.endswith(\".png\"):\n",
    "            save_faces(interval_id, frame_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "emerging-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_face_images(df_batch):\n",
    "    for idx, row in tqdm(df_batch[['interval_id', 'interval_frames_dir']].iterrows()):\n",
    "        interval_id, frames_dir = row['interval_id'], row['interval_frames_dir']\n",
    "        print(frames_dir)\n",
    "        frames = sorted(os.listdir(frames_dir))\n",
    "        for frame_filename in frames:\n",
    "            if frame_filename.endswith(\".png\"):\n",
    "                save_faces(interval_id, frame_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "worldwide-venue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 35)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inervals_batch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "second-profile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>video_id</th>\n",
       "      <th>interval_id</th>\n",
       "      <th>valid</th>\n",
       "      <th>duration</th>\n",
       "      <th>start_time_string</th>\n",
       "      <th>end_time_string</th>\n",
       "      <th>video_link</th>\n",
       "      <th>video_fn</th>\n",
       "      <th>start_time</th>\n",
       "      <th>...</th>\n",
       "      <th>interval_frames_dir</th>\n",
       "      <th>full_video_path</th>\n",
       "      <th>frames_dir_exists</th>\n",
       "      <th>frames_dir_content_size</th>\n",
       "      <th>frames_count</th>\n",
       "      <th>supposed_frames_count</th>\n",
       "      <th>missing_frames_count</th>\n",
       "      <th>has_completed_frames</th>\n",
       "      <th>pats_path</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>oliver</td>\n",
       "      <td>MepXBJjsNxs</td>\n",
       "      <td>101321</td>\n",
       "      <td>True</td>\n",
       "      <td>6.606607</td>\n",
       "      <td>00:06:46.10</td>\n",
       "      <td>00:06:52.71</td>\n",
       "      <td>http://www.youtube.com/watch?v=MepXBJjsNxs</td>\n",
       "      <td>Sugar_-_Last_Week_Tonight_with_John_Oliver_HBO...</td>\n",
       "      <td>0 days 00:06:46.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>/Users/staveshemesh/Projects/PATS_DATA/Youtube...</td>\n",
       "      <td>/Users/staveshemesh/Projects/PATS_DATA/Youtube...</td>\n",
       "      <td>True</td>\n",
       "      <td>3296</td>\n",
       "      <td>101</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/staveshemesh/Projects/PATS_DATA/Process...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>oliver</td>\n",
       "      <td>r-ERajkMXw0</td>\n",
       "      <td>101188</td>\n",
       "      <td>True</td>\n",
       "      <td>5.805806</td>\n",
       "      <td>00:03:28.40</td>\n",
       "      <td>00:03:34.21</td>\n",
       "      <td>https://www.youtube.com/watch?v=r-ERajkMXw0</td>\n",
       "      <td>Right_To_Be_Forgotten_-_Last_Week_Tonight_with...</td>\n",
       "      <td>0 days 00:03:28.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>/Users/staveshemesh/Projects/PATS_DATA/Youtube...</td>\n",
       "      <td>/Users/staveshemesh/Projects/PATS_DATA/Youtube...</td>\n",
       "      <td>True</td>\n",
       "      <td>2944</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/staveshemesh/Projects/PATS_DATA/Process...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker     video_id interval_id  valid  duration start_time_string  \\\n",
       "100  oliver  MepXBJjsNxs      101321   True  6.606607       00:06:46.10   \n",
       "66   oliver  r-ERajkMXw0      101188   True  5.805806       00:03:28.40   \n",
       "\n",
       "    end_time_string                                   video_link  \\\n",
       "100     00:06:52.71   http://www.youtube.com/watch?v=MepXBJjsNxs   \n",
       "66      00:03:34.21  https://www.youtube.com/watch?v=r-ERajkMXw0   \n",
       "\n",
       "                                              video_fn  \\\n",
       "100  Sugar_-_Last_Week_Tonight_with_John_Oliver_HBO...   \n",
       "66   Right_To_Be_Forgotten_-_Last_Week_Tonight_with...   \n",
       "\n",
       "                 start_time  ...  \\\n",
       "100  0 days 00:06:46.100000  ...   \n",
       "66   0 days 00:03:28.400000  ...   \n",
       "\n",
       "                                   interval_frames_dir  \\\n",
       "100  /Users/staveshemesh/Projects/PATS_DATA/Youtube...   \n",
       "66   /Users/staveshemesh/Projects/PATS_DATA/Youtube...   \n",
       "\n",
       "                                       full_video_path frames_dir_exists  \\\n",
       "100  /Users/staveshemesh/Projects/PATS_DATA/Youtube...              True   \n",
       "66   /Users/staveshemesh/Projects/PATS_DATA/Youtube...              True   \n",
       "\n",
       "     frames_dir_content_size  frames_count  supposed_frames_count  \\\n",
       "100                     3296           101                     99   \n",
       "66                      2944            90                     87   \n",
       "\n",
       "     missing_frames_count  has_completed_frames  \\\n",
       "100                     2                  True   \n",
       "66                      3                  True   \n",
       "\n",
       "                                             pats_path  word_count  \n",
       "100  /Users/staveshemesh/Projects/PATS_DATA/Process...          10  \n",
       "66   /Users/staveshemesh/Projects/PATS_DATA/Process...          18  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_face_images(df_inervals_batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ultimate-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['speaker', 'video_id', 'interval_id', 'valid', 'duration',\n",
       "       'start_time_string', 'end_time_string', 'video_link', 'video_fn',\n",
       "       'start_time', 'end_time', 'org_start_time', 'org_end_time',\n",
       "       'max_frames_token', 'valid_duration', 'valid_single_token_per_frame',\n",
       "       'video_downloded', 'valid_hd5', 'valid_max_token_duration',\n",
       "       'valid_frames_count', 'video_downloaded', 'interval_video_path',\n",
       "       'interval_video_downloaded', 'interval_frames_dir', 'full_video_path',\n",
       "       'frames_dir_exists', 'frames_dir_content_size', 'frames_count',\n",
       "       'supposed_frames_count', 'missing_frames_count', 'has_completed_frames',\n",
       "       'pats_path', 'word_count', 'has_annot_224', 'face_annot_224_dir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inervals_batch1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inervals_batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "applicable-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcount(path):\n",
    "    count1 = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        count1 += len(dirs)\n",
    "\n",
    "    return count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "adult-spyware",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/staveshemesh/.pyenv/versions/3.6.8/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_inervals_batch1['has_annot_224'] = df_inervals_batch1['interval_id'].apply(\n",
    "    lambda interval_id: \n",
    "        os.path.exists(resolve_interval_face_annot_224_dir(interval_id)) and\n",
    "        10 < fcount(resolve_interval_face_annot_224_dir(interval_id))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "shaped-orbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_73e89d1e_b586_11eb_8160_a683e7ab8623 caption {\n",
       "          color: navy;\n",
       "          font-size: 16px;\n",
       "    }</style><table id=\"T_73e89d1e_b586_11eb_8160_a683e7ab8623\" ><caption>Has Annotations</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >has_annot_224</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_73e89d1e_b586_11eb_8160_a683e7ab8623level0_row0\" class=\"row_heading level0 row0\" >True</th>\n",
       "                        <td id=\"T_73e89d1e_b586_11eb_8160_a683e7ab8623row0_col0\" class=\"data row0 col0\" >354</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_73e89d1e_b586_11eb_8160_a683e7ab8623level0_row1\" class=\"row_heading level0 row1\" >False</th>\n",
       "                        <td id=\"T_73e89d1e_b586_11eb_8160_a683e7ab8623row1_col0\" class=\"data row1 col0\" >77</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1594d57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_value_counts(df_inervals_batch1['has_annot_224'], 'Has Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "nearby-medication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_e8b5e976_b3e7_11eb_b9ad_a683e7ab8623 caption {\n",
       "          color: navy;\n",
       "          font-size: 16px;\n",
       "    }</style><table id=\"T_e8b5e976_b3e7_11eb_b9ad_a683e7ab8623\" ><caption>Has Annotations</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >has_annot_224</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e8b5e976_b3e7_11eb_b9ad_a683e7ab8623level0_row0\" class=\"row_heading level0 row0\" >True</th>\n",
       "                        <td id=\"T_e8b5e976_b3e7_11eb_b9ad_a683e7ab8623row0_col0\" class=\"data row0 col0\" >228</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8b5e976_b3e7_11eb_b9ad_a683e7ab8623level0_row1\" class=\"row_heading level0 row1\" >False</th>\n",
       "                        <td id=\"T_e8b5e976_b3e7_11eb_b9ad_a683e7ab8623row1_col0\" class=\"data row1 col0\" >203</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x159240320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_value_counts(df_inervals_batch1['has_annot_224'], 'Has Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "purple-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_140e674a_b3f4_11eb_8071_a683e7ab8623 caption {\n",
       "          color: navy;\n",
       "          font-size: 16px;\n",
       "    }</style><table id=\"T_140e674a_b3f4_11eb_8071_a683e7ab8623\" ><caption>Has Annotations</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >has_annot_224</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_140e674a_b3f4_11eb_8071_a683e7ab8623level0_row0\" class=\"row_heading level0 row0\" >True</th>\n",
       "                        <td id=\"T_140e674a_b3f4_11eb_8071_a683e7ab8623row0_col0\" class=\"data row0 col0\" >230</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140e674a_b3f4_11eb_8071_a683e7ab8623level0_row1\" class=\"row_heading level0 row1\" >False</th>\n",
       "                        <td id=\"T_140e674a_b3f4_11eb_8071_a683e7ab8623row1_col0\" class=\"data row1 col0\" >201</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15922b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_value_counts(df_inervals_batch1['has_annot_224'], 'Has Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "comprehensive-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in (df_inervals_batch1[df_inervals_batch1['has_annot_224']]['interval_frames_dir'] + '/*png').tolist():\n",
    "#     !rm {d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "arbitrary-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_face_images(df_batch):\n",
    "    for idx, row in tqdm(df_batch[['interval_id', 'interval_frames_dir']].iterrows()):\n",
    "        interval_id, frames_dir = row['interval_id'], row['interval_frames_dir']\n",
    "        if interval_id in ['102025', '102079', '102300', '104716', '104770', '104775', '104788', '104818', '104853', '104885', '104918', '104921']:\n",
    "            continue\n",
    "        print(frames_dir)\n",
    "        frames = sorted(os.listdir(frames_dir))\n",
    "        for frame_filename in frames:\n",
    "            if frame_filename.endswith(\".png\"):\n",
    "                save_faces(interval_id, frame_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "qualified-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_intervals=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "billion-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_faces(interval_id, frame_filename, debug=False):\n",
    "    frame_id, frame_path = resolve_paths(frame_filename, interval_id)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(frame_path)\n",
    "    except UnidentifiedImageError:\n",
    "        skip_intervals.append(interval_id)\n",
    "        return\n",
    "    boxes, probs, points = mtcnn.detect(image, landmarks=True)\n",
    "    img_draw = image.copy()\n",
    "    draw = ImageDraw.Draw(img_draw)\n",
    "    \n",
    "    for i, (box, point) in enumerate(zip(boxes, points)):\n",
    "        draw.rectangle(box.tolist(), width=5)\n",
    "        for p in point:\n",
    "            draw.rectangle((p - 10).tolist() + (p + 10).tolist(), width=10)\n",
    "        detected_face_path = resolve_detected_face_path(interval_id, frame_id, i, create=True)\n",
    "        extract_face(image, box, image_size=224, margin=70, save_path=detected_face_path)\n",
    "    \n",
    "    annotated_faces_path = resolve_annot_faces_path(interval_id, frame_id)\n",
    "    img_draw.save(annotated_faces_path)\n",
    "    \n",
    "    debug_print(debug, frame_filename, frame_id, annotated_faces_path, probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_face_images(df_inervals_batch1[~df_inervals_batch1['has_annot_224']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inervals_batch1[df_inervals_batch1['interval_id'] == '102025']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "smart-shore",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/staveshemesh/.pyenv/versions/3.6.8/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_inervals_batch1.iloc[273].has_annot_224 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-attack",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
